import streamlit as st
import os
from dotenv import load_dotenv
from io import BytesIO
import pandas as pd
import json
import tiktoken

# Importando as fun√ß√µes dos outros arquivos
from relatorio import get_token, get_workspaces_id, scan_workspace, clean_reports, upload_file
from documenta import generate_docx, generate_excel, text_to_document, Documenta, defined_prompt_fontes, defined_prompt_medidas, generate_promt_medidas, generate_promt_fontes, defined_prompt, generate_promt

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

MODELO = ""
MAX_TOKENS = 0
MAX_TOKENS_SAIDA = 0

def counttokens(text):
    # Inicializando o tokenizador para o modelo desejado (neste exemplo, GPT-4)
    encoding = tiktoken.get_encoding("cl100k_base")
    
    # Contar o n√∫mero de tokens no texto fornecido
    tokens = len(encoding.encode(text))
    
    return tokens

def configure_app():
    """Configura a apar√™ncia e o layout do aplicativo Streamlit."""    
    st.set_page_config(
        page_title="AutoDoc",
        page_icon="üìä",
        layout="wide",
        initial_sidebar_state="expanded",
    )
    st.header('Documentador de Power BI - Minhas Planilhas - 2025')
    st.write("""
    Este aplicativo facilita a organiza√ß√£o, o acompanhamento e a an√°lise de dados, fornecendo uma documenta√ß√£o completa e automatizada dos relat√≥rios de Power BI. 
    Ideal para administradores e analistas que buscam efici√™ncia e precis√£o na gera√ß√£o de documenta√ß√µes detalhadas e formatadas.
    """)

def sidebar_inputs():
    """Exibe o menu lateral para inser√ß√£o das informa√ß√µes do administrador e upload do arquivo template do Power BI."""    
    with st.sidebar:
        
        st.image("https://lawrence.eti.br/wp-content/uploads/2025/04/AutoDoc.png")
        
        # Op√ß√£o de sele√ß√£o entre Open AI e Groq para definir o modelo
        modelo = st.selectbox("Selecione o modelo:", ('gpt-4.1-nano', 'azure/gpt-4.1-nano','gpt-4.1-mini', 'gpt-4.1', 'groq/meta-llama/llama-4-maverick-17b-128e-instruct', 'gemini/gemini-2.5-flash-preview-04-17', 'claude-3-7-sonnet-20250219', 'deepseek/deepseek-chat' ))
                         
        # Op√ß√£o de sele√ß√£o entre Servi√ßo e Arquivo
        option = st.radio("Selecione a fonte de dados:", ('Power BI Template .pbit', 'Servi√ßo do Power BI'))
        
        if option == 'Power BI Template .pbit':
            app_id = None
            tenant_id = None
            secret_value = None
            uploaded_files = st.file_uploader("Apenas arquivo '.pbit' ou '.zip'", accept_multiple_files=False, type=['pbit', 'zip'], help="""

1. **Salvar com a extens√£o .pbit**: Ao salvar o arquivo, selecione a extens√£o .pbit na janela de salvamento. Isso garantir√° que seu relat√≥rio do Power BI seja salvo como um template.

2. **Exportar como Power BI Template**: Outra maneira de salvar seu relat√≥rio como um template √© atrav√©s do menu. V√° at√© o menu superior e selecione `Arquivo > Exportar > Power BI Template`. Isso abrir√° uma janela onde voc√™ poder√° definir o nome do arquivo e outras configura√ß√µes antes de salvar o template.

Usar o formato .pbit permite que voc√™ crie templates reutiliz√°veis, facilitando a cria√ß√£o de novos relat√≥rios baseados no mesmo modelo.""")
        else:
            st.write('Preencha com as informa√ß√µes do App')
            app_id = st.text_input(label='App ID')
            tenant_id = st.text_input(label='Tenant ID')
            secret_value = st.text_input(label='Secret value')
            uploaded_files = None  # Nenhum arquivo ser√° necess√°rio            

        # Set a slider to select max tokens
        max_tokens = st.sidebar.number_input('Selecione o m√°ximo de tokens de entrada:', min_value=256, max_value=10000000, value=8192, step=256)

        # Set a slider to select max tokens
        max_tokens_saida = st.sidebar.number_input('Selecione o m√°ximo de tokens de sa√≠da:', min_value=512, max_value=128000, value=8192, step=512)             
        
        ""
        "Criado por [Lawrence Teixeira](https://www.linkedin.com/in/lawrenceteixeira/)"

    return app_id, tenant_id, secret_value, uploaded_files, modelo, max_tokens, max_tokens_saida

def detailed_description():
    """Mostra uma explica√ß√£o detalhada sobre o aplicativo."""    
    st.write("""
    **Documentador de Power BI** √© uma ferramenta desenvolvida para simplificar e automatizar o processo de documenta√ß√£o de relat√≥rios do Power BI. 
    Com este aplicativo, voc√™ pode:
    
    - **Carregar seus arquivos de modelo Power BI (.pbit ou .zip)**: Fa√ßa upload dos seus arquivos de modelo diretamente no aplicativo.
    - **Gerar Documenta√ß√£o Detalhada**: Obtenha documentos completos em formatos Excel e Word, com informa√ß√µes sobre tabelas, colunas, medidas e fontes de dados.
    - **Visualiza√ß√£o Interativa**: Veja as tabelas e dados detalhados diretamente na interface do aplicativo antes de fazer o download.
    - **Efici√™ncia e Precis√£o**: Automatize o processo de documenta√ß√£o, economizando tempo e garantindo a precis√£o das informa√ß√µes.

    O aplicativo √© projetado para administradores e analistas de dados que precisam de uma forma eficiente e precisa de gerar documenta√ß√µes de alta qualidade para seus relat√≥rios do Power BI. 
    A ferramenta utiliza tecnologias avan√ßadas de processamento de dados e intelig√™ncia artificial para fornecer documenta√ß√µes claras, detalhadas e formatadas de acordo com suas necessidades.

    **Como usar o Documentador de Power BI**:
    1. Preencha as informa√ß√µes do App ID, Tenant ID e Secret Value na barra lateral.
    2. Fa√ßa o upload do arquivo de modelo Power BI (.pbit ou .zip).
    3. Visualize os dados e fa√ßa o download da documenta√ß√£o gerada em formatos Excel ou Word.

    Simplifique e automatize a documenta√ß√£o dos seus relat√≥rios do Power BI com o **Documentador de Power BI**.
    
    Criado por [Lawrence Teixeira](https://www.linkedin.com/in/lawrenceteixeira/) em 19/04/2025.
       
    """)

def sidebar_description():
    """Mostra uma descri√ß√£o resumida com bot√£o para mais informa√ß√µes na barra lateral."""    
    st.sidebar.header("Sobre o App")
    if st.sidebar.button("Informa√ß√µes"):
        st.session_state.show_description = not st.session_state.get('show_description', False)
        
    if st.session_state.get('show_description', False):
        detailed_description()
                
def main_content(headers=None, uploaded_files=None):
    """Exibe as informa√ß√µes principais do aplicativo."""    
    st.session_state['df_relationships'] = None

    if uploaded_files:
        df_normalized, df_relationships = upload_file(uploaded_files)

        # Store the df_relationships data in the session state for later use
        st.session_state['df_relationships'] = df_relationships

        if isinstance(df_normalized, pd.DataFrame):
            buttons_download(df_normalized)
        else:
            st.error("Erro ao processar o arquivo enviado. Por favor, verifique o formato do arquivo.")

    if headers:        
        workspace_dict = get_workspaces_id(headers)
        
        if workspace_dict:
            option = st.selectbox("Qual workspace voc√™ gostaria de visualizar?", list(workspace_dict.keys()), index=None, placeholder='Selecione a workspace...')
            if option:
                with st.spinner('Retornando relat√≥rio...'):
                    workspace_id = workspace_dict[option]
                    scan_response = scan_workspace(headers, workspace_id)
                    display_reports(scan_response)

def display_reports(scan_response):
    """Exibe os pain√©is e lida com a sele√ß√£o do usu√°rio."""    
    report_names = [report_info['name'] for report_info in scan_response['datasets'] if 'PbixInImportMode' in report_info['contentProviderType'] and 'Usage Metrics Report' not in report_info['name']]
    
    option = st.selectbox("Qual relat√≥rio voc√™ gostaria de visualizar?", list(report_names), index=None, placeholder='Selecione o relat√≥rio...')
    
    if option:
        df_desnormalized = clean_reports(scan_response, option)
        buttons_download(df_desnormalized)

def click_button():
    st.session_state.button = not st.session_state.button
    
# Function to recursively update the 'FonteDados' field
def update_fonte_dados(data, tables_df):
    if isinstance(data, dict):
        # Collect keys to modify in a separate list
        keys_to_update = []
        for key, value in data.items():
            if key == 'NomeTabela' and value in tables_df['NomeTabela'].to_list():
                keys_to_update.append((key, value))
            elif isinstance(value, (dict, list)):
                update_fonte_dados(value, tables_df)
        
        # Apply the modifications
        for key, value in keys_to_update:
            table_index = tables_df[tables_df['NomeTabela'] == value].index[0]
            data['FonteDados'] = tables_df['FonteDados'].iloc[table_index]
            
    elif isinstance(data, list):
        for item in data:
            update_fonte_dados(item, tables_df)  

def buttons_download(df):
    """Exibe bot√µes para download e visualiza√ß√£o dos dados processados."""    
    if not df.empty and 'ReportName' in df.columns:
        report_name = df['ReportName'].iloc[0].replace(' ', '_')
    else:
        report_name = "PBIReport"

    if 'button' not in st.session_state:
        st.session_state.button = True
    if 'show_chat' not in st.session_state:
        st.session_state.show_chat = False
    if 'doc_gerada' not in st.session_state:
        st.session_state['doc_gerada'] = False

    on = st.checkbox("Ver dados do relat√≥rio")
    if on:
        st.dataframe(df)

    verprompt_completo = st.checkbox("Mostrar Prompt")
    if verprompt_completo:
        document_text_all, dados_relatorio_PBI_medidas, dados_relatorio_PBI_fontes, measures_df, tables_df, df_colunas = text_to_document(df, max_tokens=MAX_TOKENS)
        prompt = generate_promt(document_text_all)
        st.text_area("Prompt:", value=prompt, height=300)

    mostra_total_tokens = st.checkbox("Mostrar total de tokens por intera√ß√£o")
    if mostra_total_tokens:
        document_text_all, dados_relatorio_PBI_medidas, dados_relatorio_PBI_fontes, measures_df, tables_df, df_colunas = text_to_document(df, max_tokens=MAX_TOKENS)
        total_tokens = 0
        stringmostra = ""
        conta_interacao= 0
        if counttokens(document_text_all) < MAX_TOKENS:
            conta_interacao += 1
            total_tokens += counttokens(document_text_all)
            stringmostra += f"1¬™ intera√ß√£o (prompt do relat√≥rio)      | qtde tokens: {counttokens(document_text_all):,}\n"
        else:
            for text in dados_relatorio_PBI_medidas:
                conta_interacao += 1
                total_tokens += counttokens(text)
                stringmostra += f"{conta_interacao}¬™ intera√ß√£o (prompt das medidas)      | qtde tokens: {counttokens(text):,}\n"
            for text in dados_relatorio_PBI_fontes:
                conta_interacao += 1
                total_tokens += counttokens(text)
                stringmostra += f"{conta_interacao}¬™ intera√ß√£o (prompt fonte de dados) | qtde tokens: {counttokens(text):,}\n"
        stringmostra += f"\nTotal de intera√ß√µes: {conta_interacao}\nTotal de tokens (medidas + fontes de dados) de entrada: {total_tokens:,} tokens.\n"
        st.text_area("Total de Tokens por intera√ß√£o:", value=stringmostra, height=300)

    colA, colB = st.columns(2)
    with colA:
        gerar_doc = st.button("üìù Gerar documenta√ß√£o", disabled=st.session_state.get('show_chat', False))
    with colB:
        conversar = st.button("üí¨ Chat", disabled=st.session_state.get('show_chat', False))

    if gerar_doc and not st.session_state.get('show_chat', False):
        conta_interacao = 1
        gerando = f"Gerando documenta√ß√£o usando o modelo {MODELO}, configurado com m√°ximo {MAX_TOKENS} tokens de entrada e {MAX_TOKENS_SAIDA} tokens de sa√≠da."
        with st.spinner(gerando):
            document_text_all, dados_relatorio_PBI_medidas, dados_relatorio_PBI_fontes, measures_df, tables_df, df_colunas = text_to_document(df, max_tokens=MAX_TOKENS)
            medidas_do_relatorio_df = pd.DataFrame()
            fontes_de_dados_df = pd.DataFrame()
            Uma = True
            response_info = {}
            response_tables = []
            if counttokens(document_text_all) < MAX_TOKENS:
                response = Documenta(defined_prompt(), document_text_all, MODELO, max_tokens=MAX_TOKENS, max_tokens_saida=MAX_TOKENS_SAIDA)
                conta_interacao += 1
                if Uma and 'Relatorio' in response and 'Tabelas_do_Relatorio' in response:
                    Uma = False
                    response_info = response['Relatorio']
                    response_tables = response['Tabelas_do_Relatorio']
                response_measures = response['Medidas_do_Relatorio']
                response_source = response['Fontes_de_Dados']
            else:
                for text in dados_relatorio_PBI_medidas:
                    gerando = f"{conta_interacao}¬™ intera√ß√£o, por favor aguarde..."
                    with st.spinner(gerando):
                        response = Documenta(defined_prompt_medidas(), text, MODELO, max_tokens=MAX_TOKENS, max_tokens_saida=MAX_TOKENS_SAIDA)
                        conta_interacao += 1
                        if Uma and 'Relatorio' in response and 'Tabelas_do_Relatorio' in response:
                            Uma = False
                            response_info = response['Relatorio']
                            response_tables = response['Tabelas_do_Relatorio']
                        if 'Medidas_do_Relatorio'  in response:
                            medidas_do_relatorio_df = pd.concat([medidas_do_relatorio_df, pd.DataFrame(response["Medidas_do_Relatorio"])], ignore_index=True)
                for text in dados_relatorio_PBI_fontes:
                    gerando = f"{conta_interacao}¬™ intera√ß√£o, por favor aguarde..."
                    with st.spinner(gerando):
                        response = Documenta(defined_prompt_fontes(), text, MODELO, max_tokens=MAX_TOKENS, max_tokens_saida=MAX_TOKENS_SAIDA)
                        conta_interacao += 1
                        if Uma and 'Relatorio' in response and 'Tabelas_do_Relatorio' in response:
                            print(response)
                            Uma = False
                            response_info = response['Relatorio']
                            response_tables = response['Tabelas_do_Relatorio']
                        if 'Fontes_de_Dados' in response:
                            fontes_de_dados_df = pd.concat([fontes_de_dados_df, pd.DataFrame(response["Fontes_de_Dados"])], ignore_index=True)
                response_measures = medidas_do_relatorio_df.to_dict(orient='records')
                response_source = fontes_de_dados_df.to_dict(orient='records')
            
            update_fonte_dados(response_source, tables_df)
            
            st.session_state['response_info'] = response_info
            st.session_state['response_tables'] = response_tables
            st.session_state['response_measures'] = response_measures
            st.session_state['response_source'] = response_source
            st.session_state['measures_df'] = measures_df
            st.session_state['df_colunas'] = df_colunas
            st.session_state.button = False
            st.session_state['doc_gerada'] = True  # <-- Seta flag ap√≥s gerar documenta√ß√£o
            st.session_state['modelo'] = MODELO
            st.session_state.show_chat = False

    if conversar and not st.session_state.get('show_chat', False):
        st.session_state.show_chat = True
        st.session_state['doc_gerada'] = False  # <-- Oculta op√ß√µes ao entrar no chat

    if st.session_state.show_chat:
        # --- Chat interface ---
        # Prepare chat prompt from the report
        document_text_all, _, _, _, _, _ = text_to_document(df, max_tokens=MAX_TOKENS)

        # Adiciona colunas ao contexto
        df_colunas = st.session_state.get('df_colunas')
        if df_colunas is not None and not df_colunas.empty:
            colunas_texto = '\n'.join([
                f"Tabela: {row['NomeTabela']} | Coluna: {row['NomeColuna']} | Tipo: {row['TipoDadoColuna']} | TipoColuna: {row['TipoColuna']} | Express√£o: {row['ExpressaoColuna']}"
                for _, row in df_colunas.iterrows()
            ])
        else:
            colunas_texto = 'Nenhuma coluna encontrada.'

        # Adiciona relacionamentos ao contexto
        df_relationships = st.session_state.get('df_relationships')
        if df_relationships is not None and not df_relationships.empty:
            relacionamentos_texto = '\n'.join([
                f"De: {row['FromTable']}.{row['FromColumn']} -> Para: {row['ToTable']}.{row['ToColumn']}"
                for _, row in df_relationships.iterrows()
            ])
        else:
            relacionamentos_texto = 'Nenhum relacionamento encontrado.'

        chat_prompt = f"""1 - Voc√™ √© um especialista em analisar modelos de relat√≥rio do Power BI. Sua fun√ß√£o √© responder de forma clara e detalhada qualquer pergunta feita pelo usu√°rio.\n2 - As informa√ß√µes do relat√≥rio est√£o contidas abaixo entre as tags: <INICIO DADOS RELATORIO POWER BI> e <FIM DADOS RELATORIO POWER BI>.\n3 - As suas respostas precisam ser restritas √†s informa√ß√µes contidas no relat√≥rio do Power BI.\n\nAbaixo est√£o as informa√ß√µes do relat√≥rio do Power BI para ser usado como base para responder as perguntas do usu√°rio:\n<INICIO DADOS RELATORIO POWER BI>\n{document_text_all}\n<FIM DADOS RELATORIO POWER BI>\n\n<COLUNAS DO RELATORIO>\n{colunas_texto}\n</COLUNAS DO RELATORIO>\n\n<RELACIONAMENTOS DO RELATORIO>\n{relacionamentos_texto}\n</RELACIONAMENTOS DO RELATORIO>"""
        if 'chat_messages' not in st.session_state:
            st.session_state['chat_messages'] = [
                {"role": "system", "content": chat_prompt+' sempre responder dentro de tabelas e sempre criar as descric√ß√µes das tabelas, medidas, relacionamentos, colunas e fontes de dados.'},
                {"role": "assistant", "content": f"Oi! üòä Tudo bem? Aqui √© o seu assistente do AutoDoc. Estou com o seu relat√≥rio '{report_name}' carregado na mem√¥ria! Voc√™ pode fazer perguntas referentes as tabelas, medidas DAX, colunas e relacionamentos."}
            ]
        st.markdown("<hr>", unsafe_allow_html=True)
        st.subheader("Chat")
        for msg in st.session_state['chat_messages']:
            if msg["role"] != "system":
                st.chat_message(msg["role"]).write(msg["content"])
        user_input = st.chat_input("Fa√ßa a sua pergunta...")
        if user_input:
            st.session_state['chat_messages'].append({"role": "user", "content": user_input})
            st.chat_message("user").write(user_input)
            with st.spinner('Pensando...'):
                from litellm import completion
                try:
                    response = completion(
                        model=MODELO,
                        temperature=0,
                        max_tokens=MAX_TOKENS_SAIDA,
                        messages=st.session_state['chat_messages']
                    )
                    result = response.choices[0].message.content
                except Exception as e:
                    result = f"Erro ao chamar o modelo: {str(e)}"
            msg = {"role": "assistant", "content": result}
            st.session_state['chat_messages'].append(msg)
            st.chat_message("assistant").write(result)

        st.button("‚¨ÖÔ∏è Voltar", on_click=lambda: st.session_state.update({'show_chat': False, 'doc_gerada': True}))

    # Exibe as op√ß√µes somente se a documenta√ß√£o foi gerada e o chat n√£o est√° ativo
    if st.session_state.get('doc_gerada', False) and not st.session_state.get('show_chat', False):
        verprompt = st.checkbox("Mostrar JSONs", key='mostrar_json', disabled=st.session_state.button )
        if verprompt:
            response_info_str = json.dumps(st.session_state.get('response_info', {}), indent=2)
            response_tables_str = json.dumps(st.session_state.get('response_tables', {}), indent=2)
            response_measures_str = json.dumps(st.session_state.get('response_measures', {}), indent=2)
            response_source_str = json.dumps(st.session_state.get('response_source', {}), indent=2)
            text = 'JSON com as informa√ß√µes do relat√≥rio' + '\n' + response_info_str + '\n\n' + 'JSON com as tabelas do relat√≥rio' + '\n' + response_tables_str + '\n\n' + 'JSON com as medidas do relat√≥rio' + '\n' + response_measures_str + '\n\n' + 'JSON com as fontes de dados do relat√≥rio' + '\n' + response_source_str 
            st.text_area("JSON", value=text, height=300)

        col1, col2 = st.columns(2)
        with col1:
            if st.button("üì• Exportar documenta√ß√£o para Excel", disabled=st.session_state.button):
                with st.spinner("Gerando arquivo, por favor aguarde..."):
                    buffer = generate_excel(st.session_state['response_info'], st.session_state['response_tables'], st.session_state['response_measures'], st.session_state['response_source'], st.session_state['measures_df'], st.session_state['df_relationships'], st.session_state['df_colunas'])
                    st.download_button(
                        label="üì• Baixar xlsx",
                        data=buffer,
                        file_name=report_name+'.xlsx',
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
        with col2:
            if st.button("üìÑ Exportar documenta√ß√£o para Word", disabled=st.session_state.button):
                with st.spinner("Gerando arquivo, por favor aguarde..."):
                    doc = generate_docx(st.session_state['response_info'], st.session_state['response_tables'], st.session_state['response_measures'], st.session_state['response_source'], st.session_state['measures_df'], st.session_state['df_relationships'], st.session_state['df_colunas'], st.session_state['modelo'])
                    buffer = BytesIO()
                    doc.save(buffer)
                    buffer.seek(0)
                    st.download_button(
                        label="üìÑ Baixar docx",
                        data=buffer,
                        file_name=report_name+'.docx',
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                    )

        
def main():    
    """Fun√ß√£o principal do aplicativo, onde todas as fun√ß√µes s√£o chamadas."""        
    configure_app()
            
    global API_KEY, MODELO, MAX_TOKENS, MAX_TOKENS_SAIDA

    app_id, tenant_id, secret_value, uploaded_files, modelo, max_tokens, max_tokens_saida = sidebar_inputs()
    
    MODELO = modelo
    MAX_TOKENS = max_tokens
    MAX_TOKENS_SAIDA = max_tokens_saida
            
    if app_id and tenant_id and secret_value:
        headers = get_token(app_id, tenant_id, secret_value)
        if headers:
            main_content(headers, None)
    
    if uploaded_files:
        main_content(None, uploaded_files)

    if 'show_description' not in st.session_state:
        st.session_state.show_description = False

    sidebar_description()



if __name__ == "__main__":
    main()